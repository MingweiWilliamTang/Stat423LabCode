{
    "contents" : "### install alr4 package (if need be) -- doesn't need to be done but once \n### install.packages(\"alr4\", dependencies=TRUE, repos=\"http://cran.fhcrc.org\")\n\n### load alr4 package -- needs to be done at start of R session\n\nlibrary(alr4)\n\n### reproduction of remaining Chapter 2 overheads ...\n\n### overhead II-72 ... verification that the sample statistics\n### and least squares estimates of the intercept and slope\n### for Anscombe's four data sets are virtually identical ...\n\n(n.Anscombe <- with(anscombe,length(x1)))  # 11\n\nx.bar.Anscombe.1 <- with(anscombe,mean(x1))\ny.bar.Anscombe.1 <- with(anscombe,mean(y1))\nSXX.Anscombe.1 <- with(anscombe,(n.Anscombe-1)*var(x1))\nSYY.Anscombe.1 <- with(anscombe,(n.Anscombe-1)*var(y1))\nSXY.Anscombe.1 <- with(anscombe,(n.Anscombe-1)*cov(x1,y1))\n\nx.bar.Anscombe.2 <- with(anscombe,mean(x2))\ny.bar.Anscombe.2 <- with(anscombe,mean(y2))\nSXX.Anscombe.2 <- with(anscombe,(n.Anscombe-1)*var(x2))\nSYY.Anscombe.2 <- with(anscombe,(n.Anscombe-1)*var(y2))\nSXY.Anscombe.2 <- with(anscombe,(n.Anscombe-1)*cov(x2,y2))\n\nx.bar.Anscombe.3 <- with(anscombe,mean(x3))\ny.bar.Anscombe.3 <- with(anscombe,mean(y3))\nSXX.Anscombe.3 <- with(anscombe,(n.Anscombe-1)*var(x3))\nSYY.Anscombe.3 <- with(anscombe,(n.Anscombe-1)*var(y3))\nSXY.Anscombe.3 <- with(anscombe,(n.Anscombe-1)*cov(x3,y3))\n\nx.bar.Anscombe.4 <- with(anscombe,mean(x4))\ny.bar.Anscombe.4 <- with(anscombe,mean(y4))\nSXX.Anscombe.4 <- with(anscombe,(n.Anscombe-1)*var(x4))\nSYY.Anscombe.4 <- with(anscombe,(n.Anscombe-1)*var(y4))\nSXY.Anscombe.4 <- with(anscombe,(n.Anscombe-1)*cov(x4,y4))\n\nall.equal(x.bar.Anscombe.1,x.bar.Anscombe.2)  # TRUE\nall.equal(x.bar.Anscombe.2,x.bar.Anscombe.3)  # TRUE\nall.equal(x.bar.Anscombe.3,x.bar.Anscombe.4)  # TRUE\n\nall.equal(y.bar.Anscombe.1,y.bar.Anscombe.2)  # TRUE  \nall.equal(y.bar.Anscombe.2,y.bar.Anscombe.4)  # TRUE\nall.equal(y.bar.Anscombe.2,y.bar.Anscombe.3)  # \"Mean relative difference: 0.0001211974\"\ny.bar.Anscombe.2  # 7.500909\ny.bar.Anscombe.3  # 7.5\n\nall.equal(SXX.Anscombe.1,SXX.Anscombe.2)  # TRUE\nall.equal(SXX.Anscombe.2,SXX.Anscombe.3)  # TRUE\nall.equal(SXX.Anscombe.3,SXX.Anscombe.4)  # TRUE\n\nSYY.Anscombe.1  # 41.27269\nSYY.Anscombe.2  # 41.27629\nSYY.Anscombe.3  # 41.2262 \nSYY.Anscombe.4  # 41.23249\n\nSXY.Anscombe.1  # 55.01\nSXY.Anscombe.2  # 55   \nSXY.Anscombe.3  # 54.97\nSXY.Anscombe.4  # 54.99\n\n(beta.1.hat.Anscombe.1 <- SXY.Anscombe.1/SXX.Anscombe.1)  # 0.5000909\n(beta.1.hat.Anscombe.2 <- SXY.Anscombe.2/SXX.Anscombe.2)  # 0.5      \n(beta.1.hat.Anscombe.3 <- SXY.Anscombe.3/SXX.Anscombe.3)  # 0.4997273\n(beta.1.hat.Anscombe.4 <- SXY.Anscombe.4/SXX.Anscombe.4)  # 0.4999091\n\n(beta.0.hat.Anscombe.1 <- y.bar.Anscombe.1 - beta.1.hat.Anscombe.1*x.bar.Anscombe.1)  # 3.000091\n(beta.0.hat.Anscombe.2 <- y.bar.Anscombe.2 - beta.1.hat.Anscombe.2*x.bar.Anscombe.2)  # 3.000909\n(beta.0.hat.Anscombe.3 <- y.bar.Anscombe.3 - beta.1.hat.Anscombe.3*x.bar.Anscombe.3)  # 3.002455\n(beta.0.hat.Anscombe.4 <- y.bar.Anscombe.4 - beta.1.hat.Anscombe.4*x.bar.Anscombe.4)  # 3.001727\n\n### overhead II-73 ... Anscombe's first data set\n\nwith(anscombe,plot(x1,y1,xlim=c(3,20),ylim=c(2,14),xlab=\"Predictor\", ylab=\"Response\",col=\"blue\"))\nabline(beta.0.hat.Anscombe.1,beta.1.hat.Anscombe.1,lwd=2,col=\"blue\")\n\n### overhead II-74 ... Anscombe's second data set\n\nwith(anscombe,plot(x2,y2,xlim=c(3,20),ylim=c(2,14),xlab=\"Predictor\", ylab=\"Response\",col=\"blue\"))\nabline(beta.0.hat.Anscombe.2,beta.1.hat.Anscombe.2,lwd=2,col=\"blue\")\n\n### overhead II-75 ... Anscombe's third data set\n\nwith(anscombe,plot(y3))  # to figure out index of separated point\n\nwith(anscombe,plot(x3,y3,xlim=c(3,20),ylim=c(2,14),xlab=\"Predictor\", ylab=\"Response\",col=\"blue\"))\nabline(beta.0.hat.Anscombe.3,beta.1.hat.Anscombe.3,lwd=2,col=\"blue\")\nwith(anscombe,points(x3[3],y3[3],pch=20,col=\"red\"))\n\n### overhead II-76 ... Anscombe's fourth data set\n\nwith(anscombe,plot(x4))  # to figure out index of separated point\n\nwith(anscombe,plot(x4,y4,xlim=c(3,20),ylim=c(2,14),xlab=\"Predictor\", ylab=\"Response\",col=\"blue\"))\nabline(beta.0.hat.Anscombe.4,beta.1.hat.Anscombe.4,lwd=2,col=\"blue\")\nwith(anscombe,points(x4[8],y4[8],pch=20,col=\"red\"))\n\n### overhead II-78 ... residuals vs. fitted values, data set #1\n\nfitted.Anscombe.1 <- with(anscombe,beta.0.hat.Anscombe.1 + beta.1.hat.Anscombe.1*x1)\nresiduals.Anscombe.1 <- with(anscombe,y1 - fitted.Anscombe.1)\n\nwith(anscombe,plot(fitted.Anscombe.1,residuals.Anscombe.1,xlab=\"Fitted values\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-79 ... residuals vs. predictors, data set #1\n\nwith(anscombe,plot(x1,residuals.Anscombe.1,xlab=\"Predictors\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-80 ... residuals vs. fitted values, data set #2\n\nfitted.Anscombe.2 <- with(anscombe,beta.0.hat.Anscombe.2 + beta.1.hat.Anscombe.2*x2)\nresiduals.Anscombe.2 <- with(anscombe,y2 - fitted.Anscombe.2)\n\nwith(anscombe,plot(fitted.Anscombe.2,residuals.Anscombe.2,xlab=\"Fitted values\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-81 ... residuals vs. predictors, data set #2\n\nwith(anscombe,plot(x2,residuals.Anscombe.2,xlab=\"Predictors\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-82 ... residuals vs. fitted values, data set #3\n\nfitted.Anscombe.3 <- with(anscombe,beta.0.hat.Anscombe.3 + beta.1.hat.Anscombe.3*x3)\nresiduals.Anscombe.3 <- with(anscombe,y3 - fitted.Anscombe.3)\n\nwith(anscombe,plot(fitted.Anscombe.3,residuals.Anscombe.3,xlab=\"Fitted values\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-83 ... residuals vs. predictors, data set #3\n\nwith(anscombe,plot(x3,residuals.Anscombe.3,xlab=\"Predictors\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-84 ... residuals vs. fitted values, data set #4\n\nfitted.Anscombe.4 <- with(anscombe,beta.0.hat.Anscombe.4 + beta.1.hat.Anscombe.4*x4)\nresiduals.Anscombe.4 <- with(anscombe,y4 - fitted.Anscombe.4)\n\nwith(anscombe,plot(fitted.Anscombe.4,residuals.Anscombe.4,xlab=\"Fitted values\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-85 ... residuals vs. predictors, data set #4\n\nwith(anscombe,plot(x4,residuals.Anscombe.4,xlab=\"Predictors\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-86 ... fitted values and predictions are linearly related ...\n\nwith(anscombe,plot(x1,fitted.Anscombe.1,xlab=\"Predictors\", ylab=\"Fitted values\",col=\"blue\"))\nwith(anscombe,abline(lm(fitted.Anscombe.1~x1),lwd=2))\n\nwith(anscombe,plot(x2,fitted.Anscombe.2,xlab=\"Predictors\", ylab=\"Fitted values\",col=\"blue\"))\nwith(anscombe,abline(lm(fitted.Anscombe.2~x2),lwd=2))\n\nwith(anscombe,plot(x3,fitted.Anscombe.3,xlab=\"Predictors\", ylab=\"Fitted values\",col=\"blue\"))\nwith(anscombe,abline(lm(fitted.Anscombe.3~x3),lwd=2))\n\nwith(anscombe,plot(x4,fitted.Anscombe.4,xlab=\"Predictors\", ylab=\"Fitted values\",col=\"blue\"))\nwith(anscombe,abline(lm(fitted.Anscombe.4~x4),lwd=2))\n\n### overhead II-87 ... residuals vs. case numbers, data set #1\n\nwith(anscombe,plot(1:n.Anscombe,residuals.Anscombe.1,xlab=\"Case numbers\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-88 ... residuals vs. case numbers, data set #2\n\nwith(anscombe,plot(1:n.Anscombe,residuals.Anscombe.2,xlab=\"Case numbers\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-89 ... residuals vs. case numbers, data set #3\n\nwith(anscombe,plot(1:n.Anscombe,residuals.Anscombe.3,xlab=\"Case numbers\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-90 ... residuals vs. case numbers, data set #3\n\nwith(anscombe,plot(1:n.Anscombe,residuals.Anscombe.4,xlab=\"Case numbers\", ylab=\"Residuals\",col=\"blue\"))\nabline(h=0,lty=\"dashed\")\n\n### overhead II-92 ... scatter plot for Fort Collins data\n\nlm.FC <- with(ftcollinssnow, lm(Late ~ Early))\n\nwith(ftcollinssnow,plot(Early,Late,xlab=\"Early snowfall (inches)\",ylab=\"Late snowfall (inches)\",col=\"blue\",cex=0.75))\nwith(ftcollinssnow,abline(lm.FC,lwd=2))\nwith(ftcollinssnow,abline(h=mean(Late),lwd=2,lty=\"dashed\"))\nwith(ftcollinssnow,abline(v=mean(Early),lwd=2,lty=\"dashed\"))\n\n### overhead II-93 ... residuals vs. fitted values for Fort Collins data\n\nwith(ftcollinssnow,plot(fitted(lm.FC),resid(lm.FC),xlab=\"Fitted values\",ylab=\"Residuals\",col=\"blue\",cex=0.75))\nabline(h=0,lwd=2,lty=\"dashed\",col=\"red\")\n\n### overhead II-94 ... residuals vs. predictors for Fort Collins data\n\nwith(ftcollinssnow,plot(Early,resid(lm.FC),xlab=\"Predictors\",ylab=\"Residuals\",col=\"blue\",cex=0.75))\nabline(h=0,lwd=2,lty=\"dashed\",col=\"red\")\n\n### overhead II-95 ... residuals vs. case numbers for Fort Collins data\n\nwith(ftcollinssnow,plot(1:length(Early),resid(lm.FC),xlab=\"Case numbers\",ylab=\"Residuals\",col=\"blue\",cex=0.75))\nabline(h=0,lwd=2,lty=\"dashed\",col=\"red\")\n\n### overhead II-96 ... residuals vs. responses for Fort Collins data\n\nwith(ftcollinssnow,plot(Late,resid(lm.FC),xlab=\"Responses\",ylab=\"Residuals\",col=\"blue\",cex=0.75))\nabline(h=0,lwd=2,lty=\"dashed\",col=\"red\")\n\n### overhead II-98 ... scatterplot for Forbes data ...\n\nxs.Forbes <- Forbes$bp\nys.Forbes <- log10(Forbes$pres)\nlm.Forbes <- lm(ys.Forbes ~ xs.Forbes)\n\nplot(xs.Forbes,ys.Forbes,xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.75)\nabline(lm.Forbes,lwd=2)\n\n### overhead II-99 ... residuals vs. predictor for Forbes data,\n### along with lines showing plus/minus standard error of regression\n\nn.Forbes <- length(xs.Forbes)\nSXX.Forbes <- (n.Forbes-1)*var(xs.Forbes)\nSYY.Forbes <- (n.Forbes-1)*var(ys.Forbes)\nSXY.Forbes <- (n.Forbes-1)*cov(xs.Forbes,ys.Forbes)\nRSS.Forbes <- SYY.Forbes - SXY.Forbes^2/SXX.Forbes\nsigma.2.hat.Forbes <- RSS.Forbes/(n.Forbes-2)\nse.reg.Forbes <- sqrt(sigma.2.hat.Forbes)\n\nplot(xs.Forbes,resid(lm.Forbes),ylim=c(-0.005,0.015),xlab=\"Boiling point\",ylab=\"Residuals\",col=\"blue\",cex=0.75)\nabline(h=0,lty=\"dashed\",lwd=2)\nabline(h=se.reg.Forbes*c(-1,1),lty=\"dashed\",col=\"red\",lwd=2)\n\n### overhead II-100 ... weights for slope estimates for Forbes data\n\nx.bar.Forbes <- mean(xs.Forbes)\ncs.Forbes <- (xs.Forbes -x.bar.Forbes)/SXX.Forbes\n\nplot(xs.Forbes,cs.Forbes,xlab=\"Boiling point\",ylab=expression(c[i]),typ=\"h\",col=\"blue\")\npoints(xs.Forbes,cs.Forbes,col=\"blue\",cex=0.75)\npoints(xs.Forbes[12],cs.Forbes[12],pch=20,col=\"red\",cex=0.75)\nabline(h=0,lwd=2,lty=\"dashed\")\n\n### overhead II-102 ... scatterplot for Forbes data (yet again!)\n\nplot(xs.Forbes,ys.Forbes,xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.75)\nabline(lm.Forbes,lwd=2)\n\n### overhead II-103 ... scatterplot for Forbes data sans point 12\n\nxs.sans.12 <- xs.Forbes[-12]\nys.sans.12 <- ys.Forbes[-12]\n\nlm.Forbes.sans.12 <- lm(ys.sans.12 ~ xs.sans.12)\n\nplot(xs.sans.12,ys.sans.12,xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.75)\npoints(xs.Forbes[12],ys.Forbes[12],col=\"red\",pch=\"x\",cex=0.75)\nabline(lm.Forbes.sans.12,lwd=2)\n\n### overhead II-104 ... residuals vs. predictor for all of Forbes data\n\nplot(xs.Forbes,resid(lm.Forbes),ylim=c(-0.005,0.015),xlab=\"Boiling point\",ylab=\"Residuals\",col=\"blue\",cex=0.75)\nabline(h=0,lty=\"dashed\",lwd=2)\nabline(h=se.reg.Forbes*c(-1,1),lty=\"dashed\",col=\"red\",lwd=2)\n\n### overhead II-105 ... residuals vs. predictor for Forbes data sans point 12\n\nSXX.Forbes.sans.12 <- (n.Forbes-2)*var(xs.sans.12)\nSYY.Forbes.sans.12 <- (n.Forbes-2)*var(ys.sans.12)\nSXY.Forbes.sans.12 <- (n.Forbes-2)*cov(xs.sans.12,ys.sans.12)\nRSS.Forbes.sans.12 <- SYY.Forbes.sans.12 - SXY.Forbes.sans.12^2/SXX.Forbes.sans.12\nsigma.2.hat.Forbes.sans.12 <- RSS.Forbes.sans.12/(n.Forbes-3)\nse.reg.Forbes.sans.12 <- sqrt(sigma.2.hat.Forbes.sans.12)\n\nplot(xs.sans.12,resid(lm.Forbes.sans.12),ylim=c(-0.005,0.015),xlab=\"Boiling point\",ylab=\"Residuals\",col=\"blue\",cex=0.75)\npoints(xs.Forbes[12],ys.Forbes[12]-sum(coef(lm.Forbes.sans.12)*c(1,xs.Forbes[12])),col=\"red\",pch=\"x\",cex=0.75)\nabline(h=0,lty=\"dashed\",lwd=2)\nabline(h=se.reg.Forbes.sans.12*c(-1,1),lty=\"dashed\",col=\"red\",lwd=2)\n\n### overhead II-106 ... scatterplot with prediction intervals, all of Forbes\n\nalpha.Forbes <- 0.01\nxs.pred <- seq(190,215,0.01)\n\nplot(xs.Forbes,ys.Forbes,xlim=range(xs.pred),ylim=c(1.27,1.51),xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.5)\npred.and.PIs <- predict(lm.Forbes, data.frame(xs.Forbes=xs.pred), int=\"p\", level=0.99)\nlines(xs.pred,pred.and.PIs[,\"fit\"],col=\"blue\",lwd=2)\nlines(xs.pred,pred.and.PIs[,\"lwr\"],col=\"red\",lwd=2)\nlines(xs.pred,pred.and.PIs[,\"upr\"],col=\"red\",lwd=2)\ni.pred.200 <- which(xs.pred == 200)\nabline(h=pred.and.PIs[i.pred.200,\"fit\"],col=\"blue\",lty=\"dashed\")\nabline(h=pred.and.PIs[i.pred.200,\"lwr\"],col=\"red\",lty=\"dashed\")\nabline(h=pred.and.PIs[i.pred.200,\"upr\"],col=\"red\",lty=\"dashed\")\nabline(v=200,col=\"blue\",lty=\"dashed\")\nlines(xs.pred,pred.and.PIs[,\"fit\"]-qnorm(alpha.Forbes/2,lower=FALSE)*se.reg.Forbes,lwd=2)\nlines(xs.pred,pred.and.PIs[,\"fit\"]+qnorm(alpha.Forbes/2,lower=FALSE)*se.reg.Forbes,lwd=2)\n\n### overhead II-107 ... scatterplot with prediction intervals, Forbes sans 17\n\nplot(xs.sans.12,ys.sans.12,xlim=range(xs.pred),ylim=c(1.27,1.51),xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.5)\npoints(xs.Forbes[12],ys.Forbes[12],col=\"red\",pch=\"x\",cex=0.75)\npred.and.PIs <- predict(lm.Forbes.sans.12, data.frame(xs.sans.12=xs.pred), int=\"p\", level=0.99)\nlines(xs.pred,pred.and.PIs[,\"fit\"],col=\"blue\",lwd=2)\nlines(xs.pred,pred.and.PIs[,\"lwr\"],col=\"red\",lwd=2)\nlines(xs.pred,pred.and.PIs[,\"upr\"],col=\"red\",lwd=2)\ni.pred.200 <- which(xs.pred == 200)\nabline(h=pred.and.PIs[i.pred.200,\"fit\"],col=\"blue\",lty=\"dashed\")\nabline(h=pred.and.PIs[i.pred.200,\"lwr\"],col=\"red\",lty=\"dashed\")\nabline(h=pred.and.PIs[i.pred.200,\"upr\"],col=\"red\",lty=\"dashed\")\nabline(v=200,col=\"blue\",lty=\"dashed\")\nlines(xs.pred,pred.and.PIs[,\"fit\"]-qnorm(alpha.Forbes/2,lower=FALSE)*se.reg.Forbes.sans.12,lwd=2)\nlines(xs.pred,pred.and.PIs[,\"fit\"]+qnorm(alpha.Forbes/2,lower=FALSE)*se.reg.Forbes.sans.12,lwd=2)\n\n### reproduction of Chapter 3 overheads ...\n\n### overhead III-1 ... SLR for Forbes data (yet again!) & look at model\n### with X set to zero\n\nX.Forbes <- Forbes$bp\nY.Forbes <- log10(Forbes$pres)\n\ncoef(lm.Y.X.Forbes <- lm(Y.Forbes ~ X.Forbes))\n\nround(as.vector(10^(coef(lm.Y.X.Forbes)[1])),2)\n\n### overhead III-2 ... scatterplot of Forbes data (yet again!)\n                                           \nplot(X.Forbes,Y.Forbes,xlab=\"Boiling point\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.75)\nabline(lm.Y.X.Forbes,lwd=2)\n\n### overhead III-4 ... comparison of two SLRs for Forbes data\n\nU.Forbes <- 1/(5*X.Forbes/9 + 255.37)\n\nlm.Y.U.Forbes <- lm(Y.Forbes ~ U.Forbes)\n\n### can get R^2's by looking at outputs from summary ...\n\nsummary(lm.Y.X.Forbes)  # Multiple R-squared:  0.995\nsummary(lm.Y.U.Forbes)  # Multiple R-squared:  0.9953\n\n### ... can also get R^2 by defining a function that extracts it\n### from an lm object ...\n\nstr(lm.Y.X.Forbes)  # examine innards of an lm object to see where stuff is stored ...\n\n### following function is based on equation R^2 = 1 - RSS/SYY\n\nget.R.squared <- function(lm.obj)\n    {\n        1 - sum(resid(lm.obj)^2)/sum((lm.obj$model[[1]]-mean(lm.obj$model[[1]]))^2)\n    }\n\n###\n\nget.R.squared(lm.Y.X.Forbes)  # 0.9949606\nget.R.squared(lm.Y.U.Forbes)  # 0.9952711\n\n### model based on U is a tiny bit better than the X-based model \n\n### overhead III-5 ... transformation of predictor for Forbes data\n\nplot(U.Forbes,Y.Forbes,xlab=\"1/Boiling point in Kelvin\",ylab=\"log(Pressure)\",col=\"blue\",cex=0.75)\nabline(lm.Y.U.Forbes,lwd=2)\n\n### overhead III-11 ... scatterplot matrix for BGS girls\n\nwith(BGSgirls,pairs(~ WT18 + LG18 + Soma, col=\"blue\",cex=0.75))\n\n### overhead III-12 ... scatterplot matrix with jittering\n\nset.seed(42)\nwith(BGSgirls,pairs(~ WT18 + LG18 + jitter(Soma), col=\"blue\",cex=0.75))\n\n### overhead III-13 ... enhanced scatterplot matrix (no jittering)\n\nwith(BGSgirls,scatterplotMatrix(data.frame(WT18,LG18,Soma),cex=0.75))\n\n### overhead III-14 ... scatterplot matrix for Forbes\n\npairs(~ U + X + Y, col=\"blue\", cex=0.75, data=data.frame(U=U.Forbes,X=X.Forbes,Y=Y.Forbes))\n\n### following also works, but names are different from what is on overhead\n\npairs(~ U.Forbes + X.Forbes + Y.Forbes, col=\"blue\", cex=0.75)\n\n### overhead III-15 ... enhanced scatterplot matrix for Forbes\n\nscatterplotMatrix(data.frame(U=U.Forbes,X=X.Forbes,Y=Y.Forbes))\n\n### overhead III-16 ... concocted third example (with slightly different\n### variable names to avoid confusion later on)\n\nset.seed(42)  # Q: why 42?  A: see Adams (1980)\nX1.conc <- rnorm(100)\nX2.conc <- rnorm(100)\nY.conc <- 5 - X1.conc + X2.conc + rnorm(100,sd=0.1) \n\n### overhead III-17 ... scatterplot matrix for concocted example\n\npairs(~ X1 + X2 + Y, col=\"blue\", cex=0.75, data=data.frame(X1=X1.conc,X2=X2.conc,Y=Y.conc))\n\n### following gets the same plot, but with variables named differently\n### from what is shown on III-17\n\npairs(~ X1.conc + X2.conc + Y.conc, col=\"blue\", cex=0.75)\n\n### overhead III-18 ... enhanced scatterplot matrix\n\nscatterplotMatrix(data.frame(X1=X1.conc,X2=X2.conc,Y=Y.conc), cex=0.75)\n\n### for use in overheads III-20 and beyond, let's\n### define a function that does a SLR using lm and then produces\n### a scatterplot with options to add the regression line,\n### a horizonal line at zero, a loess curve and labels for\n### special points (the function also returns the lm object) \n\nscatterplot.with.reg.line <- function(xs, ys, xlab=NULL, ylab=NULL, loess.p=TRUE, label.me=NULL, pos=3, reg.line.p=TRUE, zero.line.p=FALSE)\n  {\n    plot(xs,ys,col=\"blue\",xlab=xlab,ylab=ylab,cex=0.75)\n    ols.xs.ys <- lm(ys ~ xs)\n    if(reg.line.p) abline(reg=ols.xs.ys, col=\"black\", lwd=2)\n    if(zero.line.p) abline(h=0, lty=\"dashed\", lwd=2)\n    if(loess.p)\n      {\n        loess.xs.ys <- loess(ys ~ xs)\n        xs.order <- order(xs)\n        lines(xs[xs.order], loess.xs.ys$fitted[xs.order], col=\"red\", lwd=2) \n      }\n    if(!is.null(label.me)) text(xs[label.me], ys[label.me], label.me, pos=pos)\n    ols.xs.ys\n  }\n\n### overhead III-20 ... Soma versus WT18\n\nlm.Soma.WT18 <- with(BGSgirls, scatterplot.with.reg.line(WT18, Soma, xlab=\"WT18\", ylab=\"Soma\"))\n\n### overhead III-21\n\nlm.Soma.LG18 <- with(BGSgirls, scatterplot.with.reg.line(LG18, Soma, xlab=\"LG18\", ylab=\"Soma\"))\n\n### overhead III-22\n\nlm.LG18.WT18 <- with(BGSgirls, scatterplot.with.reg.line(WT18, LG18, xlab=\"WT18\", ylab=\"LG18\"))\n\n### overhead III-23 ... compare R^2 for Soma on WT18 and Soma on LG18 ... \n\nsummary(lm.Soma.WT18)  # Multiple R-squared:  0.5143\nsummary(lm.Soma.LG18)  # Multiple R-squared:  0.3139\n\n### ... use function get.R.squared to get R^2 ...\n\nget.R.squared(lm.Soma.WT18)  # 0.5142754\nget.R.squared(lm.Soma.LG18)  # 0.3138742\n\n### convert to percentage and round to 0.1 ...\n\nround(100*get.R.squared(lm.Soma.WT18),1)  # 51.4\nround(100*get.R.squared(lm.Soma.LG18),1)  # 31.4\n\n### overhead III-24 ... look at coefficients from two SLRs\n\nround(coef(lm.Soma.WT18),4)\n\nround(coef(lm.LG18.WT18),4)\n\n### overhead III-25 ... added-variable plot for adding LG18\n\nlm.e.e.BGS <- scatterplot.with.reg.line(resid(lm.LG18.WT18), resid(lm.Soma.WT18), xlab=expression(paste(hat (e), \" from LG18 on WT18\")), ylab=expression(paste(hat (e), \" from Soma on WT18\")))\n\n### overhead III-26 ... computations related to added-variable plot\n\ncoef(lm.e.e.BGS)\n\nall.equal(as.vector(coef(lm.e.e.BGS))[1],0)  # TRUE\n\nlm.Soma.WT18.LG18 <- with(BGSgirls, lm(Soma ~ WT18 + LG18))\n\ncoef(lm.Soma.WT18.LG18)\n\nall.equal(as.vector(coef(lm.Soma.WT18.LG18))[3],as.vector(coef(lm.e.e.BGS))[2])  # TRUE\n\nround(coef(lm.Soma.WT18),4)  #  0.7904  0.0667 \n\nround(coef(lm.Soma.LG18),4)  # -1.4117  0.1748 \n\n### overhead III-Aux-01-1 ... R^2 for two models\n\nround(100*get.R.squared(lm.Soma.WT18),1)       # 51.4\nround(100*get.R.squared(lm.Soma.WT18.LG18),1)  # 51.4\n\n### overhead III-Aux-01-2 ... look at SLR of Soma versus LG18\n\ncoef(lm.Soma.LG18)\nround(100*get.R.squared(lm.Soma.LG18),1) # 31.4\n\n### overhead III-Aux-01-3 ... added-variable plot for adding WT18\n\nlm.WT18.LG18 <- with(BGSgirls, lm(WT18 ~ LG18))\n\nlm.e.e.2.BGS <- scatterplot.with.reg.line(resid(lm.WT18.LG18), resid(lm.Soma.LG18), xlab=expression(paste(hat (e), \" from WT18 on LG18\")), ylab=expression(paste(hat (e), \" from Soma on LG18\")))\n\n### overhead III-Aux-01-4 ... computations related to added-variable plot\n\ncoef(lm.e.e.2.BGS)\n\nall.equal(as.vector(coef(lm.e.e.2.BGS))[1],0)  # TRUE\n\ncoef(lm.Soma.WT18.LG18)\n\nall.equal(as.vector(coef(lm.Soma.WT18.LG18))[2],as.vector(coef(lm.e.e.2.BGS))[2])  # TRUE\n\n### can also get both added-variable plots using R function avPlots\n\navPlots(lm.Soma.WT18.LG18)\n\n### overhead III-27 ... Y versus U for Forbes\n\nlm.Y.U.Forbes <- scatterplot.with.reg.line(U.Forbes,Y.Forbes,xlab=\"U\",ylab=\"Y\")\n\n### overhead III-28 ... Y versus X for Forbes\n\nlm.Y.X.Forbes <- scatterplot.with.reg.line(X.Forbes,Y.Forbes,xlab=\"X\",ylab=\"Y\")\n\n### overhead III-29 ... X versus U for Forbes\n\nlm.X.U.Forbes <- scatterplot.with.reg.line(U.Forbes,X.Forbes,xlab=\"U\",ylab=\"X\")\n\n### overhead III-30 ... added variable plot for adding X\n\nlm.e.e.Forbes <- scatterplot.with.reg.line(resid(lm.X.U.Forbes), resid(lm.Y.U.Forbes), xlab=expression(paste(hat (e), \" from X on U\")), ylab=expression(paste(hat (e), \" from Y on U\")))\n\n### overhead III-31 ... computations related to added-variable plot\n\ncoef(lm.e.e.Forbes)\n\nall.equal(as.vector(coef(lm.e.e.Forbes))[1],0)  # TRUE\n\nround(as.vector(coef(lm.e.e.Forbes))[2],5)  # -0.01818\n\nlm.Y.U.X.Forbes <- lm(Y.Forbes ~ U.Forbes + X.Forbes)\n\ncoef(lm.Y.U.X.Forbes)  #  2.310671e+01 -6.633712e+03 -1.817642e-02 \n\nall.equal(as.vector(coef(lm.e.e.Forbes))[2],as.vector(coef(lm.Y.U.X.Forbes)[3]))  # TRUE\n\ncoef(lm.Y.U.Forbes)  # 7.345557 -2189.990393 \n\ncoef(lm.Y.X.Forbes)  # -0.421641838  0.008956178 \n\n### can get two added-variable plots of interest using R function avPlots\n\navPlots(lm.Y.U.X.Forbes)\n\n### overhead III-32 ... Y versus X1 for concocted example\n\nlm.Y.X1.conc <- scatterplot.with.reg.line(X1.conc,Y.conc,xlab=\"X1\",ylab=\"Y\")\n\n### overhead III-33 ... Y versus X2 for concocted example\n\nlm.Y.X2.conc <- scatterplot.with.reg.line(X2.conc,Y.conc,xlab=\"X2\",ylab=\"Y\")\n\n### overhead III-34 ... X2 versus X1 for concocted example\n\nlm.X2.X1.conc <- scatterplot.with.reg.line(X1.conc,X2.conc,xlab=\"X1\",ylab=\"X2\")\n\n### overhead III-35 ... added-variable plot for adding X2\n\nlm.e.e.conc <- scatterplot.with.reg.line(resid(lm.X2.X1.conc), resid(lm.Y.X1.conc), xlab=expression(paste(hat (e), \" from X2 on X1\")), ylab=expression(paste(hat (e), \" from Y on X1\")))\n\n### overhead III-36 ... computations related to added-variable plot\n\ncoef(lm.e.e.conc)\n\nall.equal(as.vector(coef(lm.e.e.conc))[1],0)  # TRUE\n\nround(as.vector(coef(lm.e.e.conc))[2],3)  # 1.009\n\nlm.Y.X1.X2.conc <- lm(Y.conc ~ X1.conc + X2.conc)\n\nall.equal(as.vector(coef(lm.e.e.conc))[2],as.vector(coef(lm.Y.X1.X2.conc)[3]))  # TRUE\n\nround(as.vector(coef(lm.Y.X1.X2.conc)),3)  # 5.000 -1.014  1.009\n\nround(as.vector(coef(lm.Y.X1.conc)),3)  # 4.911 -0.987\n\nround(as.vector(coef(lm.Y.X2.conc)),3)  # 4.964 0.972\n\n### can get two added-variable plots of interest using R function avPlots\n\navPlots(lm.Y.X1.X2.conc)\n",
    "created" : 1453281020442.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2227781913",
    "id" : "F86F1BA0",
    "lastKnownWriteTime" : 1453281010,
    "path" : "~/Downloads/423-lab-04.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}